{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 1) IMPORTS\n",
    "############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "############################################################\n",
    "# 2) CUSTOM EFFECT SIZE FUNCTIONS\n",
    "############################################################\n",
    "\n",
    "def cohen_d(x, y):\n",
    "    \"\"\"\n",
    "    Computes Cohen's d for two independent samples x, y.\n",
    "    Formula:\n",
    "        d = (mean_x - mean_y) / pooled_std\n",
    "    where\n",
    "        pooled_std = sqrt( ((n_x - 1)*var_x + (n_y - 1)*var_y ) / (n_x + n_y - 2) ).\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "\n",
    "    n_x, n_y = len(x), len(y)\n",
    "    if n_x < 2 or n_y < 2:\n",
    "        return np.nan  # Not enough data\n",
    "\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    var_x, var_y = np.var(x, ddof=1), np.var(y, ddof=1)\n",
    "\n",
    "    # Pooled standard deviation\n",
    "    pooled_var = ((n_x - 1) * var_x + (n_y - 1) * var_y) / (n_x + n_y - 2)\n",
    "    pooled_std = np.sqrt(pooled_var)\n",
    "    if pooled_std == 0:\n",
    "        return np.nan  # Avoid divide-by-zero\n",
    "\n",
    "    return (mean_x - mean_y) / pooled_std\n",
    "\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Computes Cliff's Delta for two samples x, y.\n",
    "    Cliff's Delta = (# of x>y pairs - # of x<y pairs) / (n_x * n_y).\n",
    "    Returns float in [-1, +1].\n",
    "    \"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    y = y[~np.isnan(y)]\n",
    "\n",
    "    n_x, n_y = len(x), len(y)\n",
    "    if n_x == 0 or n_y == 0:\n",
    "        return np.nan\n",
    "\n",
    "    bigger = 0\n",
    "    smaller = 0\n",
    "    for val_x in x:\n",
    "        bigger += np.sum(val_x > y)\n",
    "        smaller += np.sum(val_x < y)\n",
    "\n",
    "    return (bigger - smaller) / float(n_x * n_y)\n",
    "\n",
    "############################################################\n",
    "# 3) STATISTICAL TEST HELPERS\n",
    "############################################################\n",
    "\n",
    "def compare_periods_parametric(series_new, series_old):\n",
    "    \"\"\"\n",
    "    Returns p-value using Welch's t-test (independent, unequal variances).\n",
    "    \"\"\"\n",
    "    t_stat, p_val = ttest_ind(series_new, series_old, equal_var=False, nan_policy='omit')\n",
    "    return p_val\n",
    "\n",
    "def compare_periods_nonparametric(series_new, series_old):\n",
    "    \"\"\"\n",
    "    Returns p-value for Mann-Whitney U test (two-sided).\n",
    "    \"\"\"\n",
    "    u_stat, p_val = mannwhitneyu(series_new, series_old, alternative='two-sided')\n",
    "    return p_val\n",
    "\n",
    "############################################################\n",
    "# 4) CORE ANALYSIS FUNCTIONS\n",
    "############################################################\n",
    "\n",
    "def run_grouping_analysis(df_new, df_old, grouping, grouping_value, threshold):\n",
    "    \"\"\"\n",
    "    Performs analysis for a specific grouping (Overall, Category, Shortname).\n",
    "    Returns a dictionary with all required metrics.\n",
    "    \"\"\"\n",
    "    if grouping == 'Overall':\n",
    "        scores_new = df_new['score']\n",
    "        scores_old = df_old['score']\n",
    "    else:\n",
    "        scores_new = df_new[df_new[grouping.lower()] == grouping_value]['score']\n",
    "        scores_old = df_old[df_old[grouping.lower()] == grouping_value]['score']\n",
    "\n",
    "    # Ensure there are enough data points\n",
    "    if len(scores_new) < 2 or len(scores_old) < 2:\n",
    "        return None  # Not enough data to perform tests\n",
    "\n",
    "    # Calculate p-values\n",
    "    param_p = compare_periods_parametric(scores_new, scores_old)\n",
    "    nonparam_p = compare_periods_nonparametric(scores_new, scores_old)\n",
    "\n",
    "    # Calculate effect sizes\n",
    "    cohens_d_val = cohen_d(scores_new, scores_old)\n",
    "    cliffs_delta_val = cliffs_delta(scores_new, scores_old)\n",
    "\n",
    "    # Calculate absolute percentage difference based on old scores\n",
    "    mean_new = np.mean(scores_new)\n",
    "    mean_old = np.mean(scores_old)\n",
    "    if mean_old == 0:\n",
    "        pct_diff = np.nan  # Avoid division by zero\n",
    "    else:\n",
    "        pct_diff = abs((mean_new - mean_old) / mean_old) * 100\n",
    "\n",
    "    # Determine if percentage difference meets/exceeds threshold\n",
    "    if pd.isna(pct_diff):\n",
    "        pct_significant = False\n",
    "    else:\n",
    "        pct_significant = pct_diff >= threshold\n",
    "\n",
    "    # Compile results\n",
    "    result = {\n",
    "        'Assessment Type': df_new['assessmenttype'].iloc[0],\n",
    "        'Grouping': grouping,\n",
    "        'Grouping Value': grouping_value,\n",
    "        'Comparison': 'EOY2024_vs_MY2024',\n",
    "        'Parametric P-Value (Raw)': param_p,\n",
    "        'Non-Parametric P-Value (Raw)': nonparam_p,\n",
    "        'Cohen\\'s d': cohens_d_val,\n",
    "        'Cliff\\'s Delta': cliffs_delta_val,\n",
    "        'Absolute % Difference': pct_diff,\n",
    "        'Threshold (%)': threshold,\n",
    "        'Significant (Threshold)': pct_significant\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "############################################################\n",
    "# 5) LOAD AND PREPARE DATA\n",
    "############################################################\n",
    "\n",
    "# Define the path to your Excel file\n",
    "file_path = r\"C:\\Users\\DavidShevchenko\\Downloads\"\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name='here')\n",
    "\n",
    "df_filtered = df[\n",
    "    (df['assessmenttype'].isin(['1', '2'])) &\n",
    "    (df['period'].isin(['x', 'y']))\n",
    "].copy()\n",
    "\n",
    "############################################################\n",
    "# 6) DEFINE GROUPINGS\n",
    "############################################################\n",
    "\n",
    "# Define the grouping levels\n",
    "grouping_levels = ['Overall', 'Category', 'Detailed']\n",
    "\n",
    "# Get unique categories and shortnames from the filtered data\n",
    "unique_categories = df_filtered['category'].dropna().unique()\n",
    "unique_shortnames = df_filtered['Detailed'].dropna().unique()\n",
    "\n",
    "############################################################\n",
    "# 7) DETERMINING DYNAMIC PERCENTAGE DIFFERENCE THRESHOLDS\n",
    "############################################################\n",
    "\n",
    "def determine_thresholds(df, grouping_levels, percentile=75):\n",
    "    thresholds = {}\n",
    "    for grouping in grouping_levels:\n",
    "        if grouping == 'Overall':\n",
    "            # Fixed threshold for Overall\n",
    "            thresholds[grouping] = 5  # Example: 5%\n",
    "        else:\n",
    "            # Calculate percentage differences for each unique value in the grouping\n",
    "            pct_diffs = []\n",
    "            if grouping == 'Category':\n",
    "                unique_values = unique_categories\n",
    "            else:\n",
    "                unique_values = unique_shortnames\n",
    "\n",
    "            for value in unique_values:\n",
    "                subset_new = df[\n",
    "                    (df['period'] == 'EOY 2024') &\n",
    "                    (df[grouping.lower()] == value)\n",
    "                ]['score']\n",
    "                subset_old = df[\n",
    "                    (df['period'] == 'MY 2024') &\n",
    "                    (df[grouping.lower()] == value)\n",
    "                ]['score']\n",
    "\n",
    "                if len(subset_new) < 1 or len(subset_old) < 1:\n",
    "                    continue  # Skip if no data\n",
    "\n",
    "                mean_new = subset_new.mean()\n",
    "                mean_old = subset_old.mean()\n",
    "\n",
    "                if mean_old == 0:\n",
    "                    continue  # Avoid division by zero\n",
    "\n",
    "                pct_diff = abs((mean_new - mean_old) / mean_old) * 100\n",
    "                pct_diffs.append(pct_diff)\n",
    "\n",
    "            if len(pct_diffs) == 0:\n",
    "                thresholds[grouping] = 0  # Default threshold if no data\n",
    "            else:\n",
    "                # Set threshold at the specified percentile\n",
    "                thresholds[grouping] = np.percentile(pct_diffs, percentile)\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "# Determine dynamic thresholds\n",
    "dynamic_thresholds = determine_thresholds(df_filtered, grouping_levels, percentile=75)\n",
    "\n",
    "############################################################\n",
    "# 8) PERFORM ANALYSIS AND COMPILE RESULTS\n",
    "############################################################\n",
    "\n",
    "# Initialize a list to store all results\n",
    "results = []\n",
    "\n",
    "# Loop through each Assessment Type\n",
    "assessment_types = df_filtered['assessmenttype'].dropna().unique()\n",
    "\n",
    "for assessment in assessment_types:\n",
    "    df_assessment_new = df_filtered[\n",
    "        (df_filtered['assessmenttype'] == assessment) &\n",
    "        (df_filtered['period'] == 'EOY 2024')\n",
    "    ]\n",
    "    df_assessment_old = df_filtered[\n",
    "        (df_filtered['assessmenttype'] == assessment) &\n",
    "        (df_filtered['period'] == 'MY 2024')\n",
    "    ]\n",
    "\n",
    "    for grouping in grouping_levels:\n",
    "        if grouping == 'Overall':\n",
    "            threshold = dynamic_thresholds[grouping]\n",
    "            result = run_grouping_analysis(\n",
    "                df_new=df_assessment_new,\n",
    "                df_old=df_assessment_old,\n",
    "                grouping=grouping,\n",
    "                grouping_value='Overall',\n",
    "                threshold=threshold\n",
    "            )\n",
    "            if result:\n",
    "                results.append(result)\n",
    "        else:\n",
    "            if grouping == 'Category':\n",
    "                unique_values = unique_categories\n",
    "            else:\n",
    "                unique_values = unique_shortnames\n",
    "            for value in unique_values:\n",
    "                threshold = dynamic_thresholds[grouping]\n",
    "                result = run_grouping_analysis(\n",
    "                    df_new=df_assessment_new[\n",
    "                        df_assessment_new[grouping.lower()] == value\n",
    "                    ],\n",
    "                    df_old=df_assessment_old[\n",
    "                        df_assessment_old[grouping.lower()] == value\n",
    "                    ],\n",
    "                    grouping=grouping,\n",
    "                    grouping_value=value,\n",
    "                    threshold=threshold\n",
    "                )\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "reporting_table = pd.DataFrame(results)\n",
    "\n",
    "############################################################\n",
    "# 9) APPLY BONFERRONI CORRECTION TO P-VALUES\n",
    "############################################################\n",
    "\n",
    "# Determine the number of tests performed\n",
    "num_tests = len(reporting_table)\n",
    "\n",
    "# Apply Bonferroni correction to parametric p-values\n",
    "reporting_table['Parametric P-Value Corrected'] = reporting_table['Parametric P-Value (Raw)'] * num_tests\n",
    "reporting_table['Parametric P-Value Corrected'] = reporting_table['Parametric P-Value Corrected'].apply(lambda x: min(x, 1))\n",
    "\n",
    "# Apply Bonferroni correction to non-parametric p-values\n",
    "reporting_table['Non-Parametric P-Value Corrected'] = reporting_table['Non-Parametric P-Value (Raw)'] * num_tests\n",
    "reporting_table['Non-Parametric P-Value Corrected'] = reporting_table['Non-Parametric P-Value Corrected'].apply(lambda x: min(x, 1))\n",
    "\n",
    "# Determine significance flags based on corrected p-values\n",
    "reporting_table['Parametric Significant'] = reporting_table['Parametric P-Value Corrected'] < 0.05\n",
    "reporting_table['Non-Parametric Significant'] = reporting_table['Non-Parametric P-Value Corrected'] < 0.05\n",
    "\n",
    "# Determine combined significance flag (both tests are significant)\n",
    "reporting_table['Combined Significant'] = reporting_table['Parametric Significant'] & reporting_table['Non-Parametric Significant']\n",
    "\n",
    "############################################################\n",
    "# 10) FINAL REPORTING TABLE STRUCTURE\n",
    "############################################################\n",
    "\n",
    "# Rearrange columns to include corrected p-values and significance flags\n",
    "reporting_table = reporting_table[[\n",
    "    'Assessment Type',\n",
    "    'Grouping',\n",
    "    'Grouping Value',\n",
    "    'Comparison',\n",
    "    'Parametric P-Value (Raw)',\n",
    "    'Non-Parametric P-Value (Raw)',\n",
    "    'Parametric P-Value Corrected',\n",
    "    'Non-Parametric P-Value Corrected',\n",
    "    'Parametric Significant',\n",
    "    'Non-Parametric Significant',\n",
    "    'Combined Significant',\n",
    "    'Cohen\\'s d',\n",
    "    'Cliff\\'s Delta',\n",
    "    'Absolute % Difference',\n",
    "    'Threshold (%)',\n",
    "    'Significant (Threshold)'\n",
    "]]\n",
    "\n",
    "############################################################\n",
    "# 11) FORMAT P-VALUES FOR CLARITY\n",
    "############################################################\n",
    "\n",
    "# Define a function to format p-values in scientific notation with 2 decimal places\n",
    "def format_pval(x):\n",
    "    if pd.isna(x):\n",
    "        return ''\n",
    "    return \"{0:.2e}\".format(x)\n",
    "\n",
    "# Apply formatting\n",
    "reporting_table['Parametric P-Value (Raw)'] = reporting_table['Parametric P-Value (Raw)'].apply(format_pval)\n",
    "reporting_table['Non-Parametric P-Value (Raw)'] = reporting_table['Non-Parametric P-Value (Raw)'].apply(format_pval)\n",
    "reporting_table['Parametric P-Value Corrected'] = reporting_table['Parametric P-Value Corrected'].apply(format_pval)\n",
    "reporting_table['Non-Parametric P-Value Corrected'] = reporting_table['Non-Parametric P-Value Corrected'].apply(format_pval)\n",
    "\n",
    "############################################################\n",
    "# 12) EXPORT THE REPORTING TABLE TO EXCEL\n",
    "############################################################\n",
    "\n",
    "# Define the output Excel file path\n",
    "output_file = r\"C:\\Users\\DavidShevchenko\\Downloads\"\n",
    "\n",
    "# Export to Excel\n",
    "reporting_table.to_excel(output_file, index=False, sheet_name='Reporting Table')\n",
    "\n",
    "# Inform the user\n",
    "print(f\"Detailed reporting table has been exported to '{output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DaveShevy-Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
