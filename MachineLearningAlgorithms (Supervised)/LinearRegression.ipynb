{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (Supervised) - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, ElasticNet, Lars, LassoLars,\n",
    "                                  OrthogonalMatchingPursuit, BayesianRidge, ARDRegression,\n",
    "                                  HuberRegressor, RANSACRegressor, TheilSenRegressor)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Importing the dataset\n",
    "data_frame = pd.read_csv(\"C:\\\\Users\\\\david\\\\OneDrive\\\\Documents\\\\GitHub\\\\Projects\\\\StatisticalAnalysis\\\\Billionaires Statistics Dataset.csv\")\n",
    "data_frame.head()\n",
    "\n",
    "# Filtering the dataset\n",
    "data_frame = data_frame[['finalWorth', 'category', 'age', 'country', 'industries']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data for Machine Learning Options\n",
    "1) Remove rows with missing values\n",
    "2) Impute missing values with mean or other statistical method. Analyze significance of imputation.\n",
    "3) Predictive Imputation - Use a model to predict missing values\n",
    "4) Using a model that supports missing values\n",
    "   1) Linear Regression requires no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>age</th>\n",
       "      <th>category_Automotive</th>\n",
       "      <th>category_Construction &amp; Engineering</th>\n",
       "      <th>category_Diversified</th>\n",
       "      <th>category_Energy</th>\n",
       "      <th>category_Fashion &amp; Retail</th>\n",
       "      <th>category_Finance &amp; Investments</th>\n",
       "      <th>category_Food &amp; Beverage</th>\n",
       "      <th>category_Gambling &amp; Casinos</th>\n",
       "      <th>...</th>\n",
       "      <th>industries_Healthcare</th>\n",
       "      <th>industries_Logistics</th>\n",
       "      <th>industries_Manufacturing</th>\n",
       "      <th>industries_Media &amp; Entertainment</th>\n",
       "      <th>industries_Metals &amp; Mining</th>\n",
       "      <th>industries_Real Estate</th>\n",
       "      <th>industries_Service</th>\n",
       "      <th>industries_Sports</th>\n",
       "      <th>industries_Technology</th>\n",
       "      <th>industries_Telecom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.989450</td>\n",
       "      <td>0.668386</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.836602</td>\n",
       "      <td>-1.066740</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.124085</td>\n",
       "      <td>-0.463218</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.412152</td>\n",
       "      <td>0.970147</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.310447</td>\n",
       "      <td>2.026311</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   finalWorth       age  category_Automotive  \\\n",
       "0   20.989450  0.668386                False   \n",
       "1   17.836602 -1.066740                 True   \n",
       "2   11.124085 -0.463218                False   \n",
       "3   10.412152  0.970147                False   \n",
       "4   10.310447  2.026311                False   \n",
       "\n",
       "   category_Construction & Engineering  category_Diversified  category_Energy  \\\n",
       "0                                False                 False            False   \n",
       "1                                False                 False            False   \n",
       "2                                False                 False            False   \n",
       "3                                False                 False            False   \n",
       "4                                False                 False            False   \n",
       "\n",
       "   category_Fashion & Retail  category_Finance & Investments  \\\n",
       "0                       True                           False   \n",
       "1                      False                           False   \n",
       "2                      False                           False   \n",
       "3                      False                           False   \n",
       "4                      False                            True   \n",
       "\n",
       "   category_Food & Beverage  category_Gambling & Casinos  ...  \\\n",
       "0                     False                        False  ...   \n",
       "1                     False                        False  ...   \n",
       "2                     False                        False  ...   \n",
       "3                     False                        False  ...   \n",
       "4                     False                        False  ...   \n",
       "\n",
       "   industries_Healthcare  industries_Logistics  industries_Manufacturing  \\\n",
       "0                  False                 False                     False   \n",
       "1                  False                 False                     False   \n",
       "2                  False                 False                     False   \n",
       "3                  False                 False                     False   \n",
       "4                  False                 False                     False   \n",
       "\n",
       "   industries_Media & Entertainment  industries_Metals & Mining  \\\n",
       "0                             False                       False   \n",
       "1                             False                       False   \n",
       "2                             False                       False   \n",
       "3                             False                       False   \n",
       "4                             False                       False   \n",
       "\n",
       "   industries_Real Estate  industries_Service  industries_Sports  \\\n",
       "0                   False               False              False   \n",
       "1                   False               False              False   \n",
       "2                   False               False              False   \n",
       "3                   False               False              False   \n",
       "4                   False               False              False   \n",
       "\n",
       "   industries_Technology  industries_Telecom  \n",
       "0                  False               False  \n",
       "1                  False               False  \n",
       "2                   True               False  \n",
       "3                   True               False  \n",
       "4                  False               False  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Convert categorical variables using one-hot encoding\n",
    "data_frame = pd.get_dummies(data_frame, columns=['category', 'country', 'industries'])\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "data_frame[['age', 'finalWorth']] = scaler.fit_transform(data_frame[['age', 'finalWorth']])\n",
    "\n",
    "data_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection and Train-Test Split\n",
    "\n",
    "# Selecting the target variable and the features\n",
    "X = data_frame.drop('finalWorth', axis=1)  # Features/INdependent variables\n",
    "y = data_frame['finalWorth']  # Target variable/dependent variables\n",
    "\n",
    "# Use mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training and Evaluation\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearRegression\n",
      "Mean Squared Error: 1.8829143152094737e+20\n",
      "R-squared: -8.016449799513389e+20\n",
      "\n",
      "\n",
      "Model: Ridge\n",
      "Mean Squared Error: 0.25080148895682375\n",
      "R-squared: -0.06777962737083842\n",
      "\n",
      "\n",
      "Model: Lasso\n",
      "Mean Squared Error: 0.24319825437313122\n",
      "R-squared: -0.03540908992165326\n",
      "\n",
      "\n",
      "Model: ElasticNet\n",
      "Mean Squared Error: 0.24319825437313122\n",
      "R-squared: -0.03540908992165326\n",
      "\n",
      "\n",
      "Model: Lars\n",
      "Mean Squared Error: 0.7710860865447838\n",
      "R-squared: -2.282875303437172\n",
      "\n",
      "\n",
      "Model: LassoLars\n",
      "Mean Squared Error: 0.24319825437313122\n",
      "R-squared: -0.03540908992165326\n",
      "\n",
      "\n",
      "Model: OrthogonalMatchingPursuit\n",
      "Mean Squared Error: 0.25453845946455145\n",
      "R-squared: -0.08368966439986192\n",
      "\n",
      "\n",
      "Model: BayesianRidge\n",
      "Mean Squared Error: 0.23721147279456867\n",
      "R-squared: -0.00992055143770254\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.733e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.477e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.167e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.378e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.614e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.552e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.541e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.136e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.036e-03, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.837e-03, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=1.739e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.593e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.432e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.426e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.416e-03, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.379e-03, with an active set of 42 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.518e-03, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.292e-03, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.144e-03, with an active set of 48 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=9.376e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=8.878e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.284e-04, with an active set of 52 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.510e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=7.361e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=6.830e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=5.677e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=5.314e-04, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.695e-04, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=4.310e-04, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.074e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=4.041e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.780e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.718e-04, with an active set of 66 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 77 iterations, i.e. alpha=3.627e-04, with an active set of 67 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=3.557e-04, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.156e-04, with an active set of 73 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.022e-04, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=2.751e-04, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=2.490e-04, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.227e-04, with an active set of 79 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=2.091e-04, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.946e-04, with an active set of 82 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.764e-04, with an active set of 84 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.672e-04, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.407e-04, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.364e-04, with an active set of 89 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.260e-04, with an active set of 90 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.240e-04, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.227e-04, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=1.171e-04, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.150e-04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 104 iterations, i.e. alpha=1.067e-04, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=9.669e-05, with an active set of 92 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=8.034e-05, with an active set of 93 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=7.609e-05, with an active set of 94 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=7.110e-05, with an active set of 94 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=6.145e-05, with an active set of 95 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=6.124e-05, with an active set of 95 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=5.508e-05, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=4.919e-05, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=3.661e-05, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=3.042e-05, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=3.014e-05, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=2.168e-05, with an active set of 100 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=1.359e-05, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 115 iterations, i.e. alpha=9.094e-06, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=6.189e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=4.344e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.606e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.338e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.756e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=1.483e-06, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=9.415e-07, with an active set of 101 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:639: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 116 iterations, i.e. alpha=2.743e-07, with an active set of 101 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ARDRegression\n",
      "Mean Squared Error: 0.2510698667201444\n",
      "R-squared: -0.06892223744586268\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\envs\\PythonConda\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: HuberRegressor\n",
      "Mean Squared Error: 0.243396839605948\n",
      "R-squared: -0.036254560444098693\n",
      "\n",
      "\n",
      "Model: RANSACRegressor\n",
      "Mean Squared Error: 6.845507249361999e+18\n",
      "R-squared: -2.914453662253369e+19\n",
      "\n",
      "\n",
      "Model: TheilSenRegressor\n",
      "Mean Squared Error: 0.23643984838267507\n",
      "R-squared: -0.006635384230645691\n",
      "\n",
      "\n",
      "Model: Pipeline\n",
      "Mean Squared Error: 7.262070492827571e+24\n",
      "R-squared: -3.091804182273858e+25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    Lars(),\n",
    "    LassoLars(),\n",
    "    OrthogonalMatchingPursuit(),\n",
    "    BayesianRidge(),\n",
    "    ARDRegression(),\n",
    "    HuberRegressor(),\n",
    "    RANSACRegressor(),\n",
    "    TheilSenRegressor(),\n",
    "    make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "for model in models:\n",
    "    train_and_evaluate(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the results for a specific model (e.g., OLS)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
